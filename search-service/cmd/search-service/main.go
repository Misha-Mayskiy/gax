package main

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"

	_ "github.com/lib/pq"
	"github.com/segmentio/kafka-go"

	"main/internal/config"
	"main/internal/domain"
	"main/internal/logger"
	"main/internal/repository/es"
	"main/internal/repository/postgres"
	"main/internal/service"
	httpserver "main/internal/transport/http"
	kafkaconsumer "main/internal/transport/kafka"
)

type SearchEvent struct {
	Type string      `json:"type"`
	Data interface{} `json:"data"`
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–æ–ø–∏–∫–æ–≤
func ensureTopics(broker string) error {
	conn, err := kafka.Dial("tcp", broker)
	if err != nil {
		return fmt.Errorf("failed to dial kafka: %w", err)
	}
	defer conn.Close()

	// –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–æ–ø–∏–∫–æ–≤
	topics := []kafka.TopicConfig{
		{
			Topic:             "messages",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "users",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "chats",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "files",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "search-events",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "file.events",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
		{
			Topic:             "media-events",
			NumPartitions:     1,
			ReplicationFactor: 1,
		},
	}

	return conn.CreateTopics(topics...)
}

func sendTestMessages(w *kafka.Writer) error {
	ctx := context.Background()
	log := logger.GetLogger()
	// 1. –¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞ "message"
	msgEvent := SearchEvent{
		Type: "message",
		Data: domain.Message{
			ID:        "msg-" + time.Now().Format("20060102150405"),
			ChatID:    "chat-001",
			AuthorID:  "user-001",
			Text:      "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
			CreatedAt: time.Now().Unix(),
		},
	}
	b1, _ := json.Marshal(msgEvent)
	if err := w.WriteMessages(ctx, kafka.Message{
		Key:   []byte("message"),
		Value: b1,
	}); err != nil {
		return fmt.Errorf("failed to write message: %w", err)
	}
	log.Info().Msg(" Test message sent to Kafka")

	// 2. –¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞ "user"
	userEvent := SearchEvent{
		Type: "user",
		Data: domain.UserIndex{
			ID:        "user-001",
			UserName:  "–ê–ª–µ–∫—Å–µ–π –ü–µ—Ç—Ä–æ–≤",
			Email:     "alexey@example.com",
			AboutMe:   "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –ü–û, —É–≤–ª–µ–∫–∞—é—Å—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π",
			UpdatedAt: time.Now().Unix(),
		},
	}
	b2, _ := json.Marshal(userEvent)
	if err := w.WriteMessages(ctx, kafka.Message{
		Key:   []byte("user"),
		Value: b2,
	}); err != nil {
		return fmt.Errorf("failed to write user: %w", err)
	}
	log.Info().Msg(" Test user sent to Kafka")

	// 3. –¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞ "chat"
	chatEvent := SearchEvent{
		Type: "chat",
		Data: domain.ChatIndex{
			ID:        "chat-001",
			Title:     "–û–±—â–∏–π —á–∞—Ç –ø—Ä–æ–µ–∫—Ç–∞",
			MemberIDs: []string{"user-001", "user-002", "user-003"},
			Kind:      "group",
			UpdatedAt: time.Now().Unix(),
		},
	}
	b3, _ := json.Marshal(chatEvent)
	if err := w.WriteMessages(ctx, kafka.Message{
		Key:   []byte("chat"),
		Value: b3,
	}); err != nil {
		return fmt.Errorf("failed to write chat: %w", err)
	}
	log.Info().Msg(" Test chat sent to Kafka")

	// 4. –¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞ "file" (–º–µ–¥–∏–∞)
	fileEvent := SearchEvent{
		Type: "file.created",
		Data: domain.FileIndex{
			ID:        "file-" + time.Now().Format("20060102150405"),
			URL:       "http://localhost:9000/media-bucket/presentations/project.pdf",
			Type:      "document",
			SizeBytes: 5242880, // 5MB
			AuthorID:  "user-001",
			ChatID:    "chat-001",
			UpdatedAt: time.Now().Unix(),
		},
	}
	b4, _ := json.Marshal(fileEvent)
	if err := w.WriteMessages(ctx, kafka.Message{
		Key:   []byte("file"),
		Value: b4,
	}); err != nil {
		return fmt.Errorf("failed to write file: %w", err)
	}
	log.Info().Msg(" Test file sent to Kafka")

	// 5. –ï—â–µ –æ–¥–∏–Ω —Ñ–∞–π–ª (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
	imageEvent := SearchEvent{
		Type: "file",
		Data: domain.FileIndex{
			ID:        "img-" + time.Now().Format("20060102150405"),
			URL:       "http://localhost:9000/media-bucket/images/architecture.png",
			Type:      "image",
			SizeBytes: 2097152, // 2MB
			AuthorID:  "user-002",
			ChatID:    "chat-001",
			UpdatedAt: time.Now().Unix(),
		},
	}
	b5, _ := json.Marshal(imageEvent)
	if err := w.WriteMessages(ctx, kafka.Message{
		Key:   []byte("image"),
		Value: b5,
	}); err != nil {
		return fmt.Errorf("failed to write image: %w", err)
	}
	log.Info().Msg(" Test image sent to Kafka")

	return nil
}

func main() {
	config := config.New()

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
	logger.Init(config.LogLevel, config.LogPretty)
	log := logger.GetLogger()
	ctx := context.Background()

	log.Info().Msg("Starting Search Service...")

	// –°–æ–∑–¥–∞—ë–º –≤—Å–µ —Ç–æ–ø–∏–∫–∏ Kafka
	log.Info().Msg("Creating Kafka topics...")
	if err := ensureTopics(config.KafkaBroker); err != nil {
		log.Warn().Err(err).Msg("Failed to create topics (they may already exist)")
	} else {
		log.Info().Msg(" Kafka topics created successfully")
	}

	// –ü—Ä–æ–¥—é—Å–µ—Ä Kafka –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
	w := kafka.NewWriter(kafka.WriterConfig{
		Brokers: []string{config.KafkaBroker},
		Topic:   "search-events", // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π —Ç–æ–ø–∏–∫ –¥–ª—è –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π
	})
	defer w.Close()

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
	log.Info().Msg(" Sending test messages to Kafka...")
	if err := sendTestMessages(w); err != nil {
		log.Fatal().Err(err).Msg("Failed to send test messages")
	}

	// –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Postgres
	log.Info().Msg(" Connecting to PostgreSQL...")
	db, err := sql.Open("postgres", config.PostgresDSN)
	if err != nil {
		log.Fatal().Err(err).Msg("Failed to connect to database")
	}
	defer db.Close()

	// –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î
	if err := db.Ping(); err != nil {
		log.Warn().Err(err).Msg(" Database connection failed, continuing without PostgreSQL")
	}

	// –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Elasticsearch
	log.Info().Msg(" Connecting to Elasticsearch...")
	esRepo, err := es.NewRepo(config.ElasticURL, log)
	if err != nil {
		log.Fatal().Err(err).Msg("Failed to connect to Elasticsearch")
	}

	// –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ Elasticsearch
	log.Info().Msg(" Ensuring Elasticsearch indices...")
	if err := esRepo.EnsureIndices(ctx); err != nil {
		log.Warn().Err(err).Msg(" Failed to create indices (they may already exist)")
	} else {
		log.Info().Msg(" Elasticsearch indices created")
	}

	pgRepo := postgres.NewRepo(db, log)

	// –ó–∞–ø—É—Å–∫–∞–µ–º Kafka consumers –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–æ–ø–∏–∫–æ–≤
	log.Info().Msg(" Starting Kafka consumers...")

	// Consumer –¥–ª—è –æ–±—â–µ–≥–æ —Ç–æ–ø–∏–∫–∞ search-events
	searchConsumer := kafkaconsumer.NewConsumer(
		[]string{config.KafkaBroker},
		"search-events",         // —Ç–æ–ø–∏–∫
		"search-consumer-group", // –≥—Ä—É–ø–ø–∞
		esRepo,
		pgRepo,
		log,
	)

	// Consumer –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π
	fileConsumer := kafkaconsumer.NewConsumer(
		[]string{config.KafkaBroker},
		"file.events",         // —Ç–æ–ø–∏–∫ –¥–ª—è –º–µ–¥–∏–∞
		"file-consumer-group", // –≥—Ä—É–ø–ø–∞
		esRepo,
		pgRepo,
		log,
	)

	// –ó–∞–ø—É—Å–∫ consumers –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≥–æ—Ä—É—Ç–∏–Ω–∞—Ö
	go func() {
		log.Info().Msg(" Search consumer started")
		searchConsumer.Run(ctx)
	}()

	go func() {
		log.Info().Msg(" File consumer started")
		fileConsumer.Run(ctx)
	}()

	// –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º HTTP —Å–µ—Ä–≤–∏—Å
	log.Info().Msg(" Starting HTTP server...")
	svc := service.NewSearchService(esRepo, log)
	server := httpserver.NewServer(svc, log)

	// –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥
	go func() {
		time.Sleep(3 * time.Second) // –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
		log.Info().Msg("üîç Running test search queries...")

		// –¢–µ—Å—Ç–æ–≤—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
		testQueries := []struct {
			query string
			typ   string
		}{
			{"pdf", "file"},
			{"presentation", "file"},
			{"–¥–∏–∞–≥—Ä–∞–º–º–∞", "file"},
			{"–ê–ª–µ–∫—Å–µ–π", "user"},
			{"–ø—Ä–æ–µ–∫—Ç", "chat"},
			{"–ø—Ä–∏–≤–µ—Ç", "message"},
		}

		for _, test := range testQueries {
			log.Info().Str("query", test.query).Str("type", test.typ).Msg("Testing search...")
			// –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤—ã–∑–æ–≤ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ HTTP
		}
	}()

	log.Info().Msgf(" Search Service HTTP listening on %s", config.HTTPPort)
	log.Info().Msgf(" Health check: http://localhost%s/health", config.HTTPPort)
	log.Info().Msgf(" Search endpoint: http://localhost%s/search?q=pdf&type=file", config.HTTPPort)

	if err := server.Listen(config.HTTPPort); err != nil {
		log.Fatal().Err(err).Msg("HTTP server failed")
	}
}
